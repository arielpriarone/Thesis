\chapter{State of the Art}
\label{ch:state_of_the_art}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/StateArt/Industry40.pdf}
    \caption{Indusstrial revolutions}
    \label{fig:ind40}    
\end{figure}

The invention of the modern steam engine in the $18^{th}$ century, marked the beginning of the first industrial revolution. The second industrial revolution, in the $19^{th}$ century, was characterized by the introduction of mass production and the assembly line. The introduction of computers and automation in factories, in the $20^{th}$ century, enabled the third industrial revolution. Nowadays, we are currently living in the $4^{th}$ industrial revolution, that embraces the industry $4.0$ vision. State of the art industries have small decentralized smart networks that make decisions automously. This is possible thanks to the \emph{Internet of Things} (\gls{iot}), smart sensors and actuators, and \emph{Big Data} analysis (\autoref{fig:ind40}). 
The data to be monitored, varies \gls{wrt} the field of application. The most common are \cite{State_Art_Coanda_2020}:
\begin{itemize}
    \item Vibration Analysis - Efficient method for detecting issues in rotating equipment.
    \item Acoustic Analysis - Detects or monitors cracks in pipes and other structures.
    \item Lubrication Oils Analysis - Analyzes particles in oils to assess component wear.
    \item Particle Analysis in Working Environment - Applied to equipment operating in fluid environments.
    \item Corrosive Analysis - Ultrasound measurements to determine corrosion in various structures.
    \item Thermal Analysis - Identifies overheating in mechanical and electrical systems.
    \item Performance Analysis - Efficient technique for pinpointing operational problems in the system.
\end{itemize}



\paragraph{Standard terminology}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/StateArt/EN13306.png}
    \caption{Standard terminology for industrial maintenance \cite{rastegari2017condition}}
    \label{fig:standard_terminology}
\end{figure}

A standard terminology used for industrial maintenance is provided by european committee for standardization with the standard \texttt{EN13306:2018} \cite{EN13306:2018}. The terminology is summarized in \autoref{fig:standard_terminology}. The most advanced maintenance technique family is \textbf{\gls{glo:conditionbasedmaintenance}}. This category include the most modern \textbf{\gls{glo:predictivemaintenance}}. Note that the definition does not imply that the \quoted{monitoring} of the system must be continuous, it may also be scheduled or not even scheduled.

The standard also defines what \textbf{\gls{glo:onlinemaintenance}} and \textbf{\gls{glo:onistemaintenance}}. All this definitions are reported in the {glossary}


\paragraph{\gls{rm} vs \gls{pm}}
\begin{figure}
    \centering
    \includegraphics[scale=0.9]{images/StateArt/lost_opportunities.pdf}
    \caption{Downtime comparison (\gls{rm} and \gls{pm})}
    \label{fig:lost_opportunities}
\end{figure}

As anticipated in the introduction, the two main approaches are \textbf{reactive maintenance} (\gls{aka} \gls{glo:correctivemaintenance}), which restores system functionality, and \textbf{proactive maintenance} (\gls{aka} \gls{glo:preventivemaintenance}), which preserves system functionality \cite{Rely_maint_book}.

The former approach leads to very high downtime \gls{wrt} the latter \cite{NIST}. For all the time a system is down, the company forfeits the opportunity to make a profit. This is called \emph{lost opportunity cost}. In reality, the total costs of downtime are even higher, because there are other costs associated with labor overhead and materials \cite{Lost_Opport_Cost}. The second approach optimizes both the pre-repair and post-repair logistics and, acting before the failure, can reduce also the total downtime. A qualitative diagram of this benefits is shown in \autoref{fig:lost_opportunities}. Other than the downtime, a more complete comparison between the advantages and disadvantages of the two approaches is shown in \autoref{tab:PM_vs_RM}.

\input{Tables/ProactiveVsReactive.tex}

\paragraph{Passive vs active maintenance}
\gls{pdm} techniques can be divided also into \emph{passive} and \emph{active}. The former uses existing sensors or add new sensors to the system and this data are just analyzed. The latter, instead, uses actuators to perturb the system and then analyzes the response. The former is more common, because it is less expensive and less invasive. The latter, instead, is more accurate but it's application is limited to special applications. The mosto common field of application of active \gls{pdm} is electrical systems, where the perturbation can be applied by injecting a current or a voltage \cite{State_Art_Hasemian_2011}.

In \cite{State_Art_Hasemian_2011}, the author gives also, as an example of active \gls{pdm}, the use the Loop Current Step Response \gls{lcsr} technique. In this test, an electrical signal in the form of a step change is sent to the sensor using a Wheatstone bridge, causing heating in the \gls{rtd} sensing element. The resulting exponential transient at the bridge output is analyzed to determine the \gls{rtd}'s response time. Beyond measuring response time, the \gls{lcsr} test can serve other purposes, such as detecting water levels in a pipe and ensuring the proper installation of temperature sensors in thermowells. Moreover, it aids in verifying timely responses to temperature changes and identifying potential degradation due to aging.

\paragraph{Models of degradation}
In \cite{Pred_Maint_Tech_Grall}, the authors proposes a decision model that optimizes the inspection schedule and replacement time to minimize the cost of failure and the unavailability. This procedure is based on two variables: the \emph{replacement threshold} and the \emph{inspection schedule}. Most of the non \gls{cbm} policy are can be emulated with specific valuaes of these two variables. This is applied to gradually deteriorating single-unit systems. The degradation is simulated with a random model that also consider the time to perform maintenance for an arbitrary period.

Another approach for caracterizing the degradation of a system is to use a stochastic model hypotesizing the use of an imperfect monitoring system. The data from the sensors are used to update the model with a Bayesian approach. The study is tested on simulated data that emulate a decaying system using Markov chains \cite{CURCURU2010989}\cite{GALANTE19981361}\cite{State_Art_Coanda_2020}.

\paragraph{Cloud based \gls{pdm}}
A relatevly new structure for \gls{pdm} is proposed in \cite{CloudBased_Wang}. The authors investigates a low cost cloud based paradigm based on the concept of \emph{mobile agents}, implemented in embedded Linux \gls{os} with open sources libraries. Compared to the traditional client-server paradigm, this approach enhances the scalability and the flexibility of the system, reducing also the need for transmission of heavy raw data.

The concept of mobile agents used in this implementation can be resumed as antonomous software entities that can migrate from one host to another, carrying their data and state \cite{CUCURULL2009712}.

The authors \cite{CloudBased_Wang} tested the mobile agent implementation with induction motors that exibited different failure modes. For example, a motor with a broken rotor bar defect is analyzed, collecting raw current measurements, envelope analysis, and spectrum analysis. Spectrum analysis poses challenges in distinguishing healthy and faulty motor signals. However, a comparison of current envelopes reveals marked differences in energy concentration associated with broken rotor bar-related frequencies. The defects analysed by the system are: broken bar, bowed rotor, unbalanced rotor, stator winding defect, defective bearing.

In the study \cite{calabreseRUL}, a cloud based \gls{pdm} system is proposed and tested on gear box in a bench test. This study perrorms anomaly detection, fault detection, and \gls{rul} prediction. Thw \gls{rul} predictions are made selecting a health indicator that is strongly correlated with the remaining life of the component.


\paragraph{Thermal imaging}
Yet another tool for detecting anomalies, mostly used for electrical devices, is gathering images of the device using an infrared camera. This method has the advantage of being non invasive. The process of images is a whole discipline, in \cite{Thermography}, the authors use a multilayered perceptron \gls{mlp} to classify $11$~features of the images. They achieved $78\%$ accuracy using the \gls{mlp} alone, that has been enhanced to $84\%$ performing a graph cut.

\paragraph{Algorithms for \gls{pdm}}
To continue the overview of state-of-the-art \gls{pdm} techniques, we will now focus on the algorithms used to analyze the data. The two bain category of algorithms are \gls{glo:trad_ml} and \gls{glo:deep} (\gls{dl}).  The survey \cite{ran2019survey} provides a comprehensive overview of the most common algorithms used in \gls{pdm}, that we summarized in \autoref{tab:ML_algorithms}, that is a merge of \cite{ran2019survey},\cite{particlefilter},\cite{yang2018particle},\cite{VONBIRGELEN2018480} and \cite{lira2011adaptive}. \gls{ann}, \gls{dt}, \gls{svm}, \gls{knn}, \gls{pf}, \gls{art} and \gls{som} are \gls{ml} algorithms, whlile \gls{ae}, \gls{cnn}, \gls{rnn}, \gls{dbn}, \gls{gan}, \gls{tl} and \gls{dlr} are deep learnign algorithms. The most common field of application of each algorithm is also reported in the table.

\input{Tables/ML_algorithms.tex}

\paragraph*{Fault / Novelty detection}

As anticipated in the \autoref{sec:preface}, another distinction in the \gls{pdm} techniques arises from the data available to build a model and/or to train it.

\subparagraph*{Fault detection}
If there is a knowledge of the peculiar features of most faults, the algorithms can be trained to detect them. As anticipated, this is called \emph{fault detection} (\gls{fd}). For example, if the monitored system is a ball bearing, it is well known in the leterature that there are four distinct fault modes, each of which has a specific frequency signature illustrated in \autoref{fig:bearing_faults} \cite{RollingSignature}:

\begin{eqnarray*}
    \text{Ballpass frequency, outer race (\gls{bpfo})}&=& \frac{n\cdot f_r}{2}\left\{1-\frac{d}{D} \cos \phi \right\}\\
    \text{Ballpass frequency, inner race (\gls{bpfi})}&=& \frac{n\cdot f_r}{2}\left\{1+\frac{d}{D} \cos \phi \right\}\\
    \text{Fundamental train frequency (\gls{ftf})}&=& \frac{f_r}{2}\left\{1-\frac{d}{D} \cos \phi \right\}\\
    \text{Ball (roller) spin frequency (\gls{bsf})}&=& \frac{D}{2\cdot d}\left\{1-\left(\frac{d}{D} \cos \phi \right)^2\right\}
\end{eqnarray*}

Where $f_r$ is the shaft speed, $n$ is the number of rolling elements, and $\phi$ is the angle of the loas from the radial plane. 

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/StateArt/bearing.jpg}
    \caption{Typycal bearing fault signals \cite{RollingSignature}}
    \label{fig:bearing_faults}
\end{figure}

An automated method for bearing dignosis hase been developed by \cite{sawalhi2008semi}. The method is parametric and can be adapted to a alrge variety of cases. In the study, it has been tested on an helicopter gearbox, an high speed ($\approx 12000$rpm) test bench application and a low speed ($\approx 1800$rpm) radar tower. 

The automated procedure \cite{sawalhi2008semi} has been extended by a more recent study \cite{schlechtingen2019automated} where the authors applied a Cepstral Editing Procedure (\gls{cep}) based signal Pre-Whitening (\gls{pw}). The framework has been tested on data collected from seventeen  wind turbines. The precedure was succesful in this case-study, the preprocessing flow applied to the timeseries, and the resulting spectral in wich the \gls{bpfi} is exploited to detect the fault, are shown in \autoref{fig:turbine_faults}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/StateArt/spectrum.png}
    \caption{Preprocessing schematic and spectrum of a bearing fault signal \cite{schlechtingen2019automated}}
    \label{fig:turbine_faults}
\end{figure}

\subparagraph*{Novelty detection}
As anticipated, most of the time there is almost no precise knowledge about the phisic of the system and data collection about faults are not available. In this case, \emph{novelty detection} (\gls{nd}) can be used. The task of detecting if a condition is \quoted{novel} can be seen as a classification problem with only one class (the data collected on the healthy system). The general idea is that if the one-class classifier is not able to classify a new observation as \quoted{healthy}, it means that the observation is \quoted{novel}.

Once the novelty detection algorithm is trained, it can be used to give an estimate of \quoted{how novel} the current behaviour of the system is. One of the major issues with \gls{nd} is to set the threshold value to decide if the observation is novel or not \cite{NoveltyReview}. This is because the value of the metric is hardly linkable to a phisical property, and the span of the metric is not known a priori.

In the \autoref{tab:novelTechniques}, we summarize the novelty detection techniques described in the comprehensive review \cite{NoveltyReview}. The review makes clear that in the field of \gls{nd} both supervised and unsupervised techniques are used. It divedes  the cathegories instead on the theory behind:
\begin{itemize}
    \item \textbf{Probabilistic} - involve a density estimation of the data;
    \item \textbf{Distance-based} - are the class of clustering techniques used traditionally for classification;
    \item \textbf{Reconstruction-based} - use a regression model to reconstruct the data, then the error is used to detect the novelty;
    \item \textbf{Domain-based} - try to define a boundary that contains all the normal data;
    \item \textbf{Information-theoretic} - is based on the idea that novel data significantly alter the information content of the dataset.
\end{itemize}

{\input{Tables/NoveltyTechniques.tex}}

The first two terminology are adopted also in the technical review on methods \cite{NoveltyTech}. This study also cathegorizes the pattern to be identified in the following classes:
\begin{itemize}
    \item \textbf{Point pattern} - are single instances that are anomalous \gls{wrt} the rest of the data;
    \item \textbf{Contextual patter} - are anomalous \gls{wrt} a specific context;
    \item \textbf{Collective pattern} - are a collection of data instances that are anomalous if considered together.
\end{itemize}

The three distinct concept are illustrated in \autoref{fig:pattern_types}.

The task of detecting the novelty is often associated with the task of predictiong the remaining useful life (\gls{rul}), before the fault become fatal for the compoment.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/StateArt/patterns.png}
    \caption{Types of patterns \cite{NoveltyTech}}
    \label{fig:pattern_types}
\end{figure}

\paragraph*{Clustering}
The most common unsupervised task is clustering. In recent years, the volume of data collected in a typical factory has increased dramatically. Clustering is a collection of tools to extract information from huge amount of unlabeled data. 

Theese algorithms can be divided in: \emph{partitioning-based} where the task is to define the boundaries between the clusters; \emph{hierarchical-based} that shows the relation between each pair of clusters depending on the medium of similarity or dissimilarity; \emph{density-based} that describes the clusters as a dense region of data points separated by low-density regions; \emph{grid-based} that apply the trasformation of the feature space into a grid before proceeeding with the clustering and \emph{model-based} that use a statistical or deep-learnign model to describe the data.

Recently, the survey \cite{Abla2019survey} provides a comprehensive overview of the most common clustering algorithms used in industrial context, with reference studies. The comparision of the study is reported in \autoref{tab:clustcomparison}.

{\small\input{Tables/ClusteringComparison.tex}}