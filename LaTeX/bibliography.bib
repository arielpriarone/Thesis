% use electronic, misc or online for links
@article{IEEEexample:article_typical,
  author = {Author, A.},
  title = {Title},
  journal = {Journal},
  year = {2022},
  volume = {1},
  number = {1},
  pages = {1-10},
  doi = {10.1234/12345678}
}
% book for entire books 
% article if in journal
% inproceedings if in conference

@Article{GridPredictMaintenance,
AUTHOR = {Mahmoud, Moamin A. and Md Nasir, Naziffa Raha and Gurunathan, Mathuri and Raj, Preveena and Mostafa, Salama A.},
TITLE = {The Current State of the Art in Research on Predictive Maintenance in Smart Grid Distribution Network: Fault's Types, Causes, and Prediction Methods—A Systematic Review},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5078},
URL = {https://www.mdpi.com/1996-1073/14/16/5078},
ISSN = {1996-1073},
DOI = {10.3390/en14165078}
}

@article{State_Art_Coanda_2020,
doi = {10.1088/1757-899X/997/1/012039},
url = {https://dx.doi.org/10.1088/1757-899X/997/1/012039},
year = {2020},
month = {dec},
publisher = {IOP Publishing},
volume = {997},
number = {1},
pages = {012039},
author = {P Coandă and M Avram and V Constantin},
title = {A state of the art of predictive maintenance techniques},
journal = {IOP Conference Series: Materials Science and Engineering},
abstract = {Nowadays in industry there is a great and increasing demand in resource management, taking into consideration the ever-growing complexity of technical systems. The concept of maintenance is one the most important topics of product development today. As the factories and the industry evolves, the need of proper maintenance plays a major factor in cost and efficiency optimization. In this paper a state of the art of maintenance techniques is presented, predictive maintenance being one of the biggest topics going forward. Predictive maintenance techniques are discussed and presented in detail creating the necessary links with nowadays industry advances: Industry 4.0.}
}

@ARTICLE{State_Art_Hasemian_2011,
  author={Hashemian, H. M.},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={State-of-the-Art Predictive Maintenance Techniques}, 
  year={2011},
  volume={60},
  number={1},
  pages={226-236},
  doi={10.1109/TIM.2010.2047662}}

@ARTICLE{Pred_Maint_Tech_Lu_Bin,
  author={Lu, Bin and Durocher, David B. and Stemper, Peter},
  journal={IEEE Industry Applications Magazine}, 
  title={Predictive maintenance techniques}, 
  year={2009},
  volume={15},
  number={6},
  pages={52-60},
  doi={10.1109/MIAS.2009.934444}}

@ARTICLE{Pred_Maint_Tech_Grall,
  author={Grall, A. and Dieulle, L. and Berenguer, C. and Roussignol, M.},
  journal={IEEE Transactions on Reliability}, 
  title={Continuous-time predictive-maintenance scheduling for a deteriorating system}, 
  year={2002},
  volume={51},
  number={2},
  pages={141-150},
  doi={10.1109/TR.2002.1011518}}

@article{CloudBased_Wang,
author = {Wang, Jinjiang and Zhang, Laibin and Duan, Lixiang and Gao, Robert},
year = {2017},
month = {06},
pages = {1125-1137},
title = {A new paradigm of cloud-based predictive maintenance for intelligent manufacturing},
volume = {28},
journal = {Journal of Intelligent Manufacturing},
doi = {10.1007/s10845-015-1066-0}
}

@inproceedings{Lost_Opport_Cost,
author = {Sillivant, Daniel},
year = {2015},
month = {01},
pages = {1-5},
title = {Reliability centered maintenance cost modeling: Lost opportunity cost},
doi = {10.1109/RAMS.2015.7105111}
}

@book{Rely_maint_book,
    author = {J. Moubray},
    title = {Reliability-Centered Maintenance},
    publisher = {Revised. Industrial Press, Inc.},
    year = {1997}
}

@Article{Umberto,
AUTHOR = {Albertin, Umberto and Pedone, Giuseppe and Brossa, Matilde and Squillero, Giovanni and Chiaberge, Marcello},
TITLE = {A Real-Time Novelty Recognition Framework Based on Machine Learning for Fault Detection},
JOURNAL = {Algorithms},
VOLUME = {16},
YEAR = {2023},
NUMBER = {2},
ARTICLE-NUMBER = {61},
URL = {https://www.mdpi.com/1999-4893/16/2/61},
ISSN = {1999-4893},
ABSTRACT = {New technologies are developed inside today&rsquo;s companies with the ascent of Industry 4.0 paradigm; Artificial Intelligence applied to Predictive Maintenance is one of these, helping factories automate their systems in detecting anomalies. The deviation of statistical features from standard operating conditions computed on collected data is a common investigation technique that companies use. The information loss due to transformation from raw data to extracted features is a problem of this approach. Furthermore, a common Predictive Maintenance framework requires historical data about failures that often do not exist, neglecting the possibility of applying it. This paper uses Artificial Intelligence as Machine Learning models to recognize when something changes in the data&rsquo;s behavior collected up to that moment, also helping companies to gather a preliminary dataset for future Predictive Maintenance implementation. The aim concerns a framework in which several sensors are used to collect data by adopting a sensor fusion approach. The architecture is composed of an optimized software system able to enhance the computation scalability and the response time regarding novelty detection. This article analyzes the proposed architecture, then explains a proof-of-concept development using a digital model; finally, two real cases are studied to show how the framework behaves in a real environment. The analysis done in this paper has an application-oriented approach; hence a company can directly use the framework in its systems.},
DOI = {10.3390/a16020061}
}

@techreport{NIST,
    author = {Douglas S. Thomas, Brian A. Weiss},
    title = {Economics of Manufacturing Machinery Maintenance },
    institution = {U.S. Department of Commerce},
    year = {2020},
    URL = {https://doi.org/10.6028/NIST.AMS.100-34}
}

@article{DBLP:journals/corr/abs-2104-04450,
  author       = {Shivam Khare and
                  Kun Cao and
                  James M. Rehg},
  title        = {Unsupervised Class-Incremental Learning Through Confusion},
  journal      = {CoRR},
  volume       = {abs/2104.04450},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.04450},
  eprinttype    = {arXiv},
  eprint       = {2104.04450},
  timestamp    = {Thu, 24 Jun 2021 17:21:06 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2104-04450.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{kmeans-improved,
  author       = {Jyoti Yadav and Monika Sharma},
  title        = {A Review of K - mean Algorithm},
  journal      = {nternational Journal of Engineering Trends and Technology (IJETT)},
  volume       = {V4(7):2972-2976},
  year         = {2013},
  url          = {www.ijettjournal.org.},
  biburl       = {www.ijettjournal.org.},
}

@inproceedings{macqueen1967some,
  title={Some methods for classification and analysis of multivariate observations},
  author={MacQueen, James and others},
  booktitle={Proceedings of the fifth Berkeley symposium on mathematical statistics and probability},
  volume={1},
  number={14},
  pages={281--297},
  year={1967},
  organization={Oakland, CA, USA}
}

@ARTICLE{Lloyd1982,
  author={Lloyd, S.},
  journal={IEEE Transactions on Information Theory}, 
  title={Least squares quantization in PCM}, 
  year={1982},
  volume={28},
  number={2},
  pages={129-137},
  doi={10.1109/TIT.1982.1056489}}

@Article{Kmeans-performances-Kriegel2017,
author={Kriegel, Hans-Peter
and Schubert, Erich
and Zimek, Arthur},
title={The (black) art of runtime evaluation: Are we comparing algorithms or implementations?},
journal={Knowledge and Information Systems},
year={2017},
month={10},
day={01},
volume={52},
number={2},
pages={341-378},
abstract={Any paper proposing a new algorithm should come with an evaluation of efficiency and scalability (particularly when we are designing methods for ``big data''). However, there are several (more or less serious) pitfalls in such evaluations. We would like to point the attention of the community to these pitfalls. We substantiate our points with extensive experiments, using clustering and outlier detection methods with and without index acceleration. We discuss what we can learn from evaluations, whether experiments are properly designed, and what kind of conclusions we should avoid. We close with some general recommendations but maintain that the design of fair and conclusive experiments will always remain a challenge for researchers and an integral part of the scientific endeavor.},
issn={0219-3116},
doi={10.1007/s10115-016-1004-2},
url={https://doi.org/10.1007/s10115-016-1004-2}
}

@article{MAHAJAN201213,
title = {The planar k-means problem is NP-hard},
journal = {Theoretical Computer Science},
volume = {442},
pages = {13-21},
year = {2012},
note = {Special Issue on the Workshop on Algorithms and Computation (WALCOM 2009)},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2010.05.034},
url = {https://www.sciencedirect.com/science/article/pii/S0304397510003269},
author = {Meena Mahajan and Prajakta Nimbhorkar and Kasturi Varadarajan},
keywords = {Clustering, -means, Planar graphs, NP-hardness},
abstract = {In the k-means problem, we are given a finite set S of points in ℜm, and integer k≥1, and we want to find k points (centers) so as to minimize the sum of the square of the Euclidean distance of each point in S to its nearest center. We show that this well-known problem is NP-hard even for instances in the plane, answering an open question posed by Dasgupta (2007) [7].}
}

@article{ahmad2015,
  author = {Peerzada Hamid Ahmad and Dr. Shilpa Dang},
  title = {Performance Evaluation of Clustering Algorithm Using Different Datasets},
  journal = {Journal of Information Engineering and Applications},
  year = {2015},
  volume = {5},
  number = {1},
  issn_print = {2224-5782},
  issn_online = {2225-0506},
  url = {http://www.iiste.org},
  note = {Research Scholar, MMICT\&BM (MCA), M.M.University (Mullana), Amballa, Haryana, India. Email: pzha.msc@gmail.com. Assistant Professor, MMICT\&BM (MCA), M.M.University (Mullana), Amballa, Haryana, India.}
}

@article{pareto,
author = {Bejarano, Lilian and Espitia, Helbert and Montenegro, Carlos},
year = {2022},
month = {03},
pages = {37},
title = {Clustering Analysis for the Pareto Optimal Front in Multi-Objective Optimization},
volume = {10},
journal = {Computation},
doi = {10.3390/computation10030037}
}

@inproceedings{Kmeanspp,
author = {Arthur, David and Vassilvitskii, Sergei},
year = {2007},
month = {01},
pages = {1027-1035},
title = {K-Means++: The Advantages of Careful Seeding},
volume = {8},
journal = {Proc. of the Annu. ACM-SIAM Symp. on Discrete Algorithms},
doi = {10.1145/1283383.1283494}
}

@article{Vornoi_Kmeans,
title = {Initialization for K-means Clustering using Voronoi Diagram},
journal = {Procedia Technology},
volume = {4},
pages = {395-400},
year = {2012},
note = {2nd International Conference on Computer, Communication, Control and Information Technology( C3IT-2012) on February 25 - 26, 2012},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2012.05.061},
url = {https://www.sciencedirect.com/science/article/pii/S2212017312003404},
author = {Damodar Reddy and Prasanta K. Jana},
keywords = {Clustering, -means, improved -means, Voronoi diagram, error rate},
abstract = {K-Means algorithm is one of the famous partitioning clustering techniques that has been studied extensively. However, the major problem with this method that it cannot ensure the global optimum results due to the random selection of initial cluster centers. In this paper, we present a novel method that selects the initial cluster centers with the help of Voronoi diagram constructed from the given set of data points. The initial cluster centers are effectively selected from those points which lie on the boundary of higher radius Voronoi circles. As a result, the proposed method automates the selection of the initial cluster centers to supply them for K-means. The proposed method is experimented on various artificial (hand-made) as well as real world data sets of various dimensions. It is observed that it is able to produce better clustering results than the traditional K-means and the improved K-means.}
}

@INPROCEEDINGS{Kmeans_linear,
  author={Pakhira, Malay K.},
  booktitle={2014 International Conference on Computational Intelligence and Communication Networks}, 
  title={A Linear Time-Complexity k-Means Algorithm Using Cluster Shifting}, 
  year={2014},
  volume={},
  number={},
  pages={1047-1051},
  doi={10.1109/CICN.2014.220}}

@inproceedings{Kmeans_vornoi_japan,
author = {Inaba, Mary and Katoh, Naoki and Imai, Hiroshi},
title = {Applications of Weighted Voronoi Diagrams and Randomization to Variance-Based k-Clustering: (Extended Abstract)},
year = {1994},
isbn = {0897916484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/177424.178042},
doi = {10.1145/177424.178042},
abstract = {In this paper we consider thek-clustering problem for a set S of n points i=(xi) in thed-dimensional space with variance-based errors as clustering criteria, motivated from the color quantization problem of computing a color lookup table for frame buffer display. As the inter-cluster criterion to minimize, the sum on intra-cluster errors over every cluster is used, and as the intra-cluster criterion of a cluster Sj,|Sj|α-1 ΣpiϵSj || xi - x(Sj)||2is considered, where ||·|| is the L2 norm and x(Sj) is the centroid of points in Sj, i.e., (1/|Sj|)Σp ∈Sjxi. The cases of α=1,2 correspond to the sum of squared errors and the all-pairs sum of squared errors, respectively.The k-clustering problem under the criterion with α=1,2 are treated in a unified manner by characterizing the optimum solution to the kclustering problem by the ordinary Euclidean Voronoi diagram and the weighted Voronoi diagram with both multiplicative and additive weights. With this framework, the problem is related to the generalized primary shutter function for the Voronoi diagrams. The primary shutter function is shown to be O(nO(kd)), which implies that, for fixed k, this clustering problem can be solved in a polynomial time. For the problem with the most typical intra-cluster criterion of the sum of squared errors, we also present an efficient randomized algorithm which, roughly speaking, finds an ∈–approximate 2–clustering in O(n(1/∈)d) time, which is quite practical and may be used to real large-scale problems such as the color quantization problem.},
booktitle = {Proceedings of the Tenth Annual Symposium on Computational Geometry},
pages = {332–339},
numpages = {8},
location = {Stony Brook, New York, USA},
series = {SCG '94}
}

@techreport{berkhin2002survey,
  author = {Pavel Berkhin},
  title = {Survey of clustering data mining techniques},
  institution = {Accrue Software},
  address = {San Jose, CA},
  year = {2002}
}

@article{Abla2019survey,
title = {A survey of clustering algorithms for an industrial context},
journal = {Procedia Computer Science},
volume = {148},
pages = {291-302},
year = {2019},
note = {The second international conference on intelligent computing in data sciences, ICDS2018},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919300225},
author = {Abla Chouni Benabdellah and Asmaa Benghabrit and Imane Bouhaddou},
keywords = {Clustering algorithms, Unsupervised learning, Sparse dataset, Aircraft, Automotive, Logistics, Industrial datasets.}}

@article{kanungo2004local,
  author = {Tapas Kanungo and David M. Mount and Nathan S. Netanyahu and Christine D. Piatko and Ruth Silverman and Angela Y. Wu},
  title = {A local search approximation algorithm for k-means clustering},
  journal = {Comput. Geom.},
  volume = {28},
  number = {2-3},
  pages = {89--112},
  year = {2004}
}

@inproceedings{ostrovsky2006effectiveness,
  author = {R. Ostrovsky and Y. Rabani and L. Schulman and C. Swamy},
  title = {The Effectiveness of Lloyd-type Methods for the k-Means Problem},
  booktitle = {Symposium on Foundations of Computer Science},
  year = {2006}
}

@book{hands-on-geron2022,
  author = {Aurelien Geron},
  title = {Hands-On Machine Learning With Scikit-Learn, Keras \& TensorFlow},
  publisher = {O'Reilly Media},
  year = {2022},
  binding = {Paperback / Softback},
  pages = {850},
  language = {English},
  isbn = {9781098125974}
}

@inproceedings{kmeans-accelerated,
author = {Elkan, Charles},
title = {Using the Triangle Inequality to Accelerate K-Means},
year = {2003},
isbn = {1577351894},
publisher = {AAAI Press},
abstract = {The k-means algorithm is by far the most widely used method for discovering clusters in data. We show how to accelerate it dramatically, while still always computing exactly the same result as the standard algorithm. The accelerated algorithm avoids unnecessary distance calculations by applying the triangle inequality in two different ways, and by keeping track of lower and upper bounds for distances between points and centers. Experiments show that the new algorithm is effective for datasets with up to 1000 dimensions, and becomes more and more effective as the number k of clusters increases. For k ≥ 20 it is many times faster than the best previously known accelerated k-means method.},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {147–153},
numpages = {7},
location = {Washington, DC, USA},
series = {ICML'03}
}

@inproceedings{Sculley2010,
author = {Sculley, D.},
title = {Web-Scale k-Means Clustering},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772862},
doi = {10.1145/1772690.1772862},
abstract = {We present two modifications to the popular k-means clustering algorithm to address the extreme requirements for latency, scalability, and sparsity encountered in user-facing web applications. First, we propose the use of mini-batch optimization for k-means clustering. This reduces computation cost by orders of magnitude compared to the classic batch algorithm while yielding significantly better solutions than online stochastic gradient descent. Second, we achieve sparsity with projected gradient descent, and give a fast ε-accurate projection onto the L1-ball. Source code is freely available: http://code.google.com/p/sofia-ml},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {1177–1178},
numpages = {2},
keywords = {unsupervised clustering, sparse solutions, scalability},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}


@article{romanycia1985heuristic,
  title={What is a heuristic?},
  author={Romanycia, Marc HJ and Pelletier, Francis Jeffry},
  journal={Computational intelligence},
  volume={1},
  number={1},
  pages={47--58},
  year={1985},
  publisher={Wiley Online Library}
}

@online{edge_computing_accenture,
  author = {Accenture},
  title = {What is edge computing?},
  url = {https://www.accenture.com/us-en/insights/cloud/edge-computing-index#:~:text=Edge%20computing%20is%20an%20emerging,led%20results%20in%20real%20time.}
}

@misc{triple_expansion_engine,
  author       = {Ferguson Brothers Ltd.},
  title        = {Triple Expansion Reciprocating Steam Engine of Engine Grab Hopper Dredger Anadrian},
  year         = {1951},
  howpublished = {Photograph},
  note         = {Malta Maritime Museum Collection, Wikimedia Commons},
  url          = {https://commons.wikimedia.org/wiki/File:Triple_expansion_reciprocating_steam_engine_Anadrian_MMM_n03.jpg},
  organization = {Wikimedia Commons},
  copyright    = {© Marie-Lan Nguyen / Wikimedia Commons / CC-BY 2.5},
  license      = {Creative Commons Attribution 2.5 Generic},
}

@online{evosite,
  title        = {Evosite Control Rooms, Control Consoles \& Ergonomic Chairs},
  year         = {2023},
  url          = {https://www.evosite.net/},
  organization = {Evosite, Inc.},
  note         = {Accessed: \today},
}

@article{steam_engine,
  author       = {Elizabeth Peterson},
  title        = {Who Invented the Steam Engine?},
  journal      = {Live Science},
  year         = {2014},
  month        = {03},
  day          = {19},
  url          = {https://www.livescience.com/44144-who-invented-the-steam-engine.html},
}

@inproceedings{dbscan,
  title={A density-based algorithm for discovering clusters in large spatial databases with noise},
  author={Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"o}rg and Xu, Xiaowei and others},
  booktitle={kdd},
  volume={96},
  number={34},
  pages={226--231},
  year={1996}
}

@book{lazar2009linearly,
  author       = {Alina Lazar and Bradley A. Shellito},
  title        = {Linearly Separable Data},
  booktitle    = {Handbook of Research on Geoinformatics},
  publisher    = {IGI Global},
  year         = {2009},
  pages        = {7},
  chapter      = {14},
  doi          = {10.4018/978-1-59140-995-3.ch014},
  abstract     = {Support Vector Machines (SVM) are powerful tools for classification of data. This article describes the functionality of SVM including their design and operation. SVM have been shown to provide high classification accuracies and have good generalization capabilities. SVM can classify linearly separable data as well as nonlinearly separable data through the use of the kernel function. The advantages of using SVM are discussed along with the standard types of kernel functions. Furthermore, the effectiveness of applying SVM to large, spatial datasets derived from Geographic Information Systems (GIS) is also described. Future trends and applications are also discussed – the described extracted dataset contains seven independent variables related to urban development plus a class label which denotes the urban areas versus the rural areas. This large dataset, with over a million instances really proves the generalization capabilities of the SVM methods. Also, the spatial property allows experts to analyze the error signal.},
}

@INPROCEEDINGS{dbscanlogm,
  author={Liu, Bing},
  booktitle={2006 International Conference on Machine Learning and Cybernetics}, 
  title={A Fast Density-Based Clustering Algorithm for Large Databases}, 
  year={2006},
  volume={},
  number={},
  pages={996-1000},
  doi={10.1109/ICMLC.2006.258531}}

  @INPROCEEDINGS{iforest,
  author={Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
  booktitle={2008 Eighth IEEE International Conference on Data Mining}, 
  title={Isolation Forest}, 
  year={2008},
  volume={},
  number={},
  pages={413-422},
  doi={10.1109/ICDM.2008.17}}

@inproceedings{10.1145/342009.335388,
author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J\"{o}rg},
title = {LOF: Identifying Density-Based Local Outliers},
year = {2000},
isbn = {1581132174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/342009.335388},
doi = {10.1145/342009.335388},
abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
booktitle = {Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data},
pages = {93–104},
numpages = {12},
keywords = {database mining, outlier detection},
location = {Dallas, Texas, USA},
series = {SIGMOD '00}
}

@article{breunig2000lof,
author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J\"{o}rg},
title = {LOF: Identifying Density-Based Local Outliers},
year = {2000},
issue_date = {June 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/335191.335388},
doi = {10.1145/335191.335388},
abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
journal = {SIGMOD Rec.},
month = {05},
pages = {93–104},
numpages = {12},
keywords = {outlier detection, database mining}
}

@article{mullerOneClassSVM,
  title={An Introduction to Kernel-Based Learning Algorithms},
  author={M{\"u}ller, Klaus-Robert and Mika, Sebastian and R{\"a}tsch, Gunnar and Tsuda, Koji and Sch{\"o}lkopf, Bernhard},
  journal={IEEE TRANSACTIONS ON NEURAL NETWORKS},
  volume={12},
  number={2},
  pages={181},
  year={2001}
}

@article{IMSpaper,
title = {Wavelet filter-based weak signature detection method and its application on rolling element bearing prognostics},
journal = {Journal of Sound and Vibration},
volume = {289},
number = {4},
pages = {1066-1090},
year = {2006},
issn = {0022-460X},
doi = {https://doi.org/10.1016/j.jsv.2005.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0022460X0500221X},
author = {Hai Qiu and Jay Lee and Jing Lin and Gang Yu},
abstract = {De-noising and extraction of the weak signature are crucial to fault prognostics in which case features are often very weak and masked by noise. The wavelet transform has been widely used in signal de-noising due to its extraordinary time-frequency representation capability. In this paper, the performance of wavelet decomposition-based de-noising and wavelet filter-based de-noising methods are compared based on signals from mechanical defects. The comparison result reveals that wavelet filter is more suitable and reliable to detect a weak signature of mechanical impulse-like defect signals, whereas the wavelet decomposition de-noising method can achieve satisfactory results on smooth signal detection. In order to select optimal parameters for the wavelet filter, a two-step optimization process is proposed. Minimal Shannon entropy is used to optimize the Morlet wavelet shape factor. A periodicity detection method based on singular value decomposition (SVD) is used to choose the appropriate scale for the wavelet transform. The signal de-noising results from both simulated signals and experimental data are presented and both support the proposed method.}
}

@article{Maintenance_cat,
author = {Tiddens, Wieger and Braaksma, Jan and Tinga, Tiedo},
address = {Bradford, West Yorkshire, England.},
issn = {1355-2511},
journal = {Journal of quality in maintenance engineering.},
number = {1},
publisher = {MCB University Press,},
title = {Exploring predictive maintenance applications in industry},
volume = {28},
year = {2022},
doi={10.1108/JQME-05-2020-0029},
url={https://doi.org/10.1108/JQME-05-2020-0029}
}

@techreport{EN13306:2018,
  title = {Maintenance - Maintenance terminology},
  author = {{CEN/TC 319}},
  institution = {European Committee for Standardization (CEN)},
  year = {2018},
  type = {CEN Standard},
  number = {EN 13306:2018},
  note = {English, French, and German language},
  pages = {93}
}

@phdthesis{rastegari2017condition,
  author = {Rastegari, Ali},
  title = {Condition Based Maintenance in the Manufacturing Industry: From Strategy to Implementation},
  school = {Mälardalen University},
  year = {2017},
  type = {PhD Thesis},
  number = {242},
  series = {Mälardalen University Press Dissertations},
  address = {School of Innovation, Design and Engineering},
  publisher = {Mälardalen University},
  note = {ISBN 978-91-7485-355-1, ISSN 1651-4238},
  url = {https://www.researchgate.net/publication/321883047},
}

@article{CUCURULL2009712,
title = {Agent mobility architecture based on IEEE-FIPA standards},
journal = {Computer Communications},
volume = {32},
number = {4},
pages = {712-729},
year = {2009},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2008.11.038},
url = {https://www.sciencedirect.com/science/article/pii/S014036640800618X},
author = {J. Cucurull and R. Martí and G. Navarro-Arribas and S. Robles and B. Overeinder and J. Borrell},
keywords = {Mobile agents, Mobility, Interoperability, Agent middleware, Agent standards},
}