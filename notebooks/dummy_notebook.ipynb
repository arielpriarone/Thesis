{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "no such item for Cursor instance",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ariel\\Documents\\Courses\\Tesi\\Code\\notebooks\\dummy_notebook.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/Courses/Tesi/Code/notebooks/dummy_notebook.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_data \u001b[39m=\u001b[39m MLA\u001b[39m.\u001b[39mcol_train\u001b[39m.\u001b[39mfind_one({\u001b[39m'\u001b[39m\u001b[39m_id\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mtraining set\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/Courses/Tesi/Code/notebooks/dummy_notebook.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m train_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# if the training set is empty, initialize it with the oldest snapshot\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/Courses/Tesi/Code/notebooks/dummy_notebook.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     snap \u001b[39m=\u001b[39m MLA\u001b[39m.\u001b[39;49mcol_features\u001b[39m.\u001b[39;49mfind()\u001b[39m.\u001b[39;49msort(\u001b[39m'\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m'\u001b[39;49m,pymongo\u001b[39m.\u001b[39;49mASCENDING)\u001b[39m.\u001b[39;49mlimit(\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39;49m]  \u001b[39m# get the oldest snapshot\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/Courses/Tesi/Code/notebooks/dummy_notebook.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     snap[\u001b[39m'\u001b[39m\u001b[39m_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining set\u001b[39m\u001b[39m'\u001b[39m                                                      \u001b[39m# rename it for initializing the training set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/Courses/Tesi/Code/notebooks/dummy_notebook.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     MLA\u001b[39m.\u001b[39mcol_train\u001b[39m.\u001b[39minsert_one(snap)                                                  \u001b[39m# insert it in the training set   \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymongo\\cursor.py:760\u001b[0m, in \u001b[0;36mCursor.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m clone:\n\u001b[0;32m    759\u001b[0m         \u001b[39mreturn\u001b[39;00m doc\n\u001b[1;32m--> 760\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mno such item for Cursor instance\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    761\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindex \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m cannot be applied to Cursor instances\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m index)\n",
      "\u001b[1;31mIndexError\u001b[0m: no such item for Cursor instance"
     ]
    }
   ],
   "source": [
    "import src\n",
    "import pymongo\n",
    "from pymongo.collection import Collection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from rich import print\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# connect to the database\n",
    "MLA = src.models.MLA(r\"C:\\Users\\ariel\\Documents\\Courses\\Tesi\\Code\\config.yaml\")\n",
    "\n",
    "train_data = MLA.col_train.find_one({'_id': 'training set'})\n",
    "\n",
    "if train_data is None:  # if the training set is empty, initialize it with the oldest snapshot\n",
    "    snap = MLA.col_features.find().sort('timestamp',pymongo.ASCENDING).limit(1)[0]  # get the oldest snapshot\n",
    "    snap['_id']='training set'                                                      # rename it for initializing the training set\n",
    "    MLA.col_train.insert_one(snap)                                                  # insert it in the training set   \n",
    "    print(\"Training set initialized\") \n",
    "else:                   # append healty documents to the dataset\n",
    "    cursor = MLA.col_features.find().sort('timestamp',pymongo.ASCENDING)  # get the oldest snapshot\n",
    "    for snap in cursor:\n",
    "        if isinstance(train_data['timestamp'],list):                     # if the training set is a list, pass\n",
    "            pass\n",
    "        else:                                                            # convert everityng to list\n",
    "            train_data['timestamp'] = [train_data['timestamp']]\n",
    "            for sensor in MLA.sensors:\n",
    "                for feature in train_data[sensor].keys():\n",
    "                    train_data[sensor][feature] = [train_data[sensor][feature]]          \n",
    "        train_data['timestamp'].append(snap['timestamp'])                  # append the timestamp\n",
    "        for sensor in MLA.sensors:\n",
    "            for feature in train_data[sensor].keys():\n",
    "                train_data[sensor][feature].append(snap[sensor][feature])  # append the sensor data\n",
    "        MLA.col_features.delete_one({'_id': snap['_id']})                  # delete the snapshot from the features collection\n",
    "   \n",
    "    MLA.col_train.replace_one({'_id': 'training set'}, train_data)         # replace the training set with the updated one                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Scaler for sensor <span style=\"color: #008000; text-decoration-color: #008000\">'Bearing 1 x'</span> saved correctly\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Scaler for sensor \u001b[32m'Bearing 1 x'\u001b[0m saved correctly\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Scaler for sensor <span style=\"color: #008000; text-decoration-color: #008000\">'Bearing 1 y'</span> saved correctly\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Scaler for sensor \u001b[32m'Bearing 1 y'\u001b[0m saved correctly\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Scaler for sensor <span style=\"color: #008000; text-decoration-color: #008000\">'Bearing 2 x'</span> saved correctly\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Scaler for sensor \u001b[32m'Bearing 2 x'\u001b[0m saved correctly\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now this script scales the data\n",
    "train_data = MLA.col_train.find_one({'_id': 'training set'})             # get the training set\n",
    "if train_data is None:\n",
    "    raise Exception('Training set not initialized')\n",
    "train_data_scaled = train_data.copy()                                   # copy the training set\n",
    "train_data_scaled['_id'] = 'training set scaled'                        # rename it\n",
    "# scale the features\n",
    "StdScaler: Dict[str, StandardScaler]= {}\n",
    "for sensor in MLA.sensors:\n",
    "    StdScaler[sensor] = StandardScaler()\n",
    "    data = np.array(list(train_data[sensor].values()))      # the scaler wants the data in the form (n_samples, n_features)\n",
    "    StdScaler[sensor].fit(data.transpose())                              # fit the scaler\n",
    "    data_scaled = StdScaler[sensor].transform(data.transpose()).transpose()         # the scaler returns the data in the form (n_features, n_samples)\n",
    "    data_scaled = data_scaled.tolist()                                  # convert the data to list    \n",
    "\n",
    "    for indx, feature in enumerate(train_data_scaled[sensor].keys()):\n",
    "        train_data_scaled[sensor][feature] = data_scaled[indx]         # the scaler returns the data in the form (n_features, n_samples)\n",
    "\n",
    "# save the scaled data\n",
    "MLA.col_train.delete_many({\"_id\": 'training set scaled'}) \n",
    "MLA.col_train.insert_one(train_data_scaled) \n",
    "\n",
    "# save the scaler\n",
    "pickled_data = pickle.dumps(StdScaler)\n",
    "try:\n",
    "    MLA.col_train.insert_one({'_id': 'StandardScaler_pickled', 'data': pickled_data})\n",
    "except:\n",
    "    MLA.col_train.replace_one({'_id': 'StandardScaler_pickled'}, {'_id': 'StandardScaler_pickled', 'data': pickled_data})\n",
    "retrieved_data: Collection | None = MLA.col_train.find_one({'_id': 'StandardScaler_pickled'})\n",
    "if retrieved_data is None:\n",
    "    raise Exception('Scaler not found')\n",
    "else:\n",
    "    StdScaler_retrieve: Dict[str, StandardScaler] = pickle.loads(retrieved_data['data'])\n",
    "\n",
    "# check if the scaler perform correctly    \n",
    "for sensor in MLA.sensors:\n",
    "    data = np.array(list(train_data[sensor].values()))      # the scaler wants the data in the form (n_samples, n_features)\n",
    "    data_scaled = StdScaler[sensor].transform(data.transpose()).transpose()         # the scaler returns the data in the form (n_features, n_samples)\n",
    "    data_scaled_retrieve = StdScaler_retrieve[sensor].transform(data.transpose()).transpose()         # the scaler returns the data in the form (n_features, n_samples)\n",
    "    if not data_scaled.tolist() == data_scaled_retrieve.tolist():\n",
    "        raise Exception('Scaler not saved correctly')\n",
    "    else:\n",
    "        print(f\"Scaler for sensor '{sensor}' saved correctly\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
